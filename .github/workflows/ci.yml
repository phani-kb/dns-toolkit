name: DNS Toolkit Daily Processing

# - Scheduled runs: full-pipeline mode with publishing
# - Push to main: use-cache mode without publishing (avoids cache conflicts)
# - Manual dispatch: user-selected mode with conditional publishing (refresh-cache and use-cache don't publish)
# - Pull Request: test-only mode

on:
  schedule:
    - cron: '0 14 * * *'  # Daily at 2 PM UTC
  workflow_dispatch:
    inputs:
      mode:
        description: 'Pipeline mode'
        required: false
        default: 'full-pipeline'
        type: choice
        options:
          - 'full-pipeline'
          - 'use-cache'
          - 'refresh-cache'
  push:
    branches: [main]
  pull_request:
    branches: [main]

permissions:
  contents: read

concurrency:
  group: dns-toolkit-pipeline
  cancel-in-progress: false

env:
  GO_VERSION: "1.23"
  COVERAGE_THRESHOLD: 80
  GOLANGCI_LINT_VERSION: v2.1.6

jobs:
  test-and-build:
    name: Test and Build
    runs-on: ubuntu-latest
    outputs:
      should-publish: ${{ steps.determine-mode.outputs.should-publish }}
      pipeline-mode: ${{ steps.determine-mode.outputs.pipeline-mode }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Install golangci-lint
        run: |
          curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | \
          sh -s -- -b $(go env GOPATH)/bin ${{ env.GOLANGCI_LINT_VERSION }}

      - name: Cache lint results
        uses: actions/cache@v4
        with:
          path: ~/.cache/golangci-lint
          key: ${{ runner.os }}-golangci-lint-${{ hashFiles('.golangci.yml', 'go.sum') }}
          restore-keys: |
            ${{ runner.os }}-golangci-lint-

      - name: Lint, Build, and Test
        env:
          DNS_TOOLKIT_TEST_MODE: true
          DNS_TOOLKIT_TEST_CONFIG_PATH: ${{ github.workspace }}/testdata/config.yml
        run: |
          echo "Running linter..."
          golangci-lint run ./... --timeout=5m
          
          echo "Building application..."
          go build ./...
          
          echo "Running tests with coverage..."
          PACKAGES=$(go list ./... | grep -v "/mocks" | grep -v "constants")
          go test -v -race -coverprofile=coverage.out -covermode=atomic $PACKAGES
          
          # Filter out test helpers from coverage
          if [ -f coverage.out ]; then
            echo "Filtering coverage report..."
            grep -v "test_helpers.go" coverage.out > filtered_coverage.out
            mv filtered_coverage.out coverage.out
          fi

      - name: Check coverage
        run: |
          if [ -f coverage.out ]; then
            COVERAGE=$(go tool cover -func=coverage.out | grep total: | awk '{print $3}' | sed 's/%//')
            echo "Coverage: ${COVERAGE}%"
            if (( $(echo "$COVERAGE < $COVERAGE_THRESHOLD" | bc -l) )); then
              echo "::error::Coverage ${COVERAGE}% is below threshold ${COVERAGE_THRESHOLD}%"
              exit 1
            fi
            echo "::notice::Coverage check passed: ${COVERAGE}%"
          else
            echo "::warning::No coverage file found"
          fi

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.out
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          verbose: false
          override_commit: ${{ github.sha }}

      - name: Determine pipeline mode and publishing status
        id: determine-mode
        run: |
          # Default to test-only and no publish
          MODE="test-only"
          PUBLISH="false"
          MESSAGE="Other event - tests only"

          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            MODE="test-only"
            PUBLISH="false"
            MESSAGE="Pull request - tests only"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            MODE="${{ github.event.inputs.mode }}"
            if [[ "$MODE" == "refresh-cache" || "$MODE" == "use-cache" ]]; then
              PUBLISH="false"
            else
              PUBLISH="true"
            fi
            MESSAGE="Manual dispatch - Mode: $MODE"
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            MODE="full-pipeline"
            PUBLISH="true"
            MESSAGE="Scheduled event - Mode: $MODE"
          elif [[ "${{ github.event_name }}" == "push" && "${{ github.ref }}" == "refs/heads/main" ]]; then
            MODE="use-cache"
            PUBLISH="false"
            MESSAGE="Push to main - Mode: $MODE (use cache, no publish)"
          fi
          
          echo "::notice::$MESSAGE"
          echo "pipeline-mode=$MODE" >> $GITHUB_OUTPUT
          echo "should-publish=$PUBLISH" >> $GITHUB_OUTPUT

  publish:
    name: DNS Toolkit Pipeline
    runs-on: ubuntu-latest
    needs: test-and-build
    if: needs.test-and-build.outputs.pipeline-mode != 'test-only'
    timeout-minutes: 20
    permissions:
      contents: write
      actions: read
    
    env:
      PIPELINE_MODE: ${{ needs.test-and-build.outputs.pipeline-mode }}
      SHOULD_PUBLISH: ${{ needs.test-and-build.outputs.should-publish }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          persist-credentials: true

      - name: Configure Git
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          git config pull.rebase false
          git config push.default simple

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Build DNS toolkit and prepare data directories
        run: |
          echo "Building DNS toolkit..."
          go build -o bin/dns-toolkit .
          chmod +x bin/dns-toolkit
          mkdir -p data/{download,output}
          echo "Build completed successfully"

      - name: Display pipeline mode summary
        run: |
          echo "## Pipeline Mode: ${{ env.PIPELINE_MODE }}" >> $GITHUB_STEP_SUMMARY
          echo "**Publishing**: ${{ env.SHOULD_PUBLISH }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          case "${{ env.PIPELINE_MODE }}" in
            "use-cache")
              echo "- **Actions**: Restore cache, skip download, process" >> $GITHUB_STEP_SUMMARY
              echo "- **Publishing**: Disabled (to avoid cache conflicts unless explicitly true)" >> $GITHUB_STEP_SUMMARY
              echo "- **Requirement**: Cache must exist or pipeline will fail" >> $GITHUB_STEP_SUMMARY
              ;;
            "refresh-cache")
              echo "- **Actions**: Download fresh data, process, save cache" >> $GITHUB_STEP_SUMMARY
              echo "- **Publishing**: Disabled (focus on cache refresh)" >> $GITHUB_STEP_SUMMARY
              ;;
            "full-pipeline")
              echo "- **Actions**: Download fresh data, process, publish, save cache" >> $GITHUB_STEP_SUMMARY
              echo "- **Note**: This is the default mode for scheduled runs" >> $GITHUB_STEP_SUMMARY
              ;;
          esac

      - name: Restore data cache
        uses: actions/cache/restore@v4
        id: cache-restore
        with:
          path: |
            data/download
            data/download_summary.json
          key: data-download-${{ runner.os }}-${{ hashFiles('data/config/sources*.json') }}-v3
          restore-keys: |
            data-download-${{ runner.os }}-${{ hashFiles('data/config/sources*.json') }}-
            data-download-${{ runner.os }}-

      - name: Validate cache (for use-cache & refresh-cache modes)
        if: env.PIPELINE_MODE == 'use-cache' || env.PIPELINE_MODE == 'refresh-cache'
        run: |
          echo "Validating cache availability..."
          if [[ "${{ steps.cache-restore.outputs.cache-hit }}" != "true" ]]; then
            echo "::error::Cache MISS. '${{ env.PIPELINE_MODE }}' mode requires an existing cache."
            exit 1
          fi
          
          if [[ ! -d "data/download" || -z "$(ls -A data/download)" ]]; then
            echo "::error::Cache hit reported, but data/download directory is empty or missing."
            exit 1
          fi
          
          if [[ "${{ env.PIPELINE_MODE }}" == "use-cache" && ! -f "data/download_summary.json" ]]; then
            echo "::error::'use-cache' mode requires 'data/download_summary.json' but it's missing from cache."
            exit 1
          fi
          
          echo "✅ Cache validated successfully."
          echo "Cache contains $(find data/download -type f 2>/dev/null | wc -l) files."
          if [[ -f "data/download/.cache_timestamp" ]]; then
            echo "Cache timestamp: $(cat data/download/.cache_timestamp)"
          fi

      - name: Backup data files
        if: env.PIPELINE_MODE == 'full-pipeline' && needs.test-and-build.outputs.should-publish == 'true'
        run: |
          echo "Backing up data files for branch switching..."
          mkdir -p /tmp/data-backup
          
          # Backup download directory and summary file
          if [[ -d "data/download" ]]; then
            cp -r data/download /tmp/data-backup/ 2>/dev/null || true
            echo "Backed up data/download directory"
          fi
          
          if [[ -f "data/download_summary.json" ]]; then
            cp data/download_summary.json /tmp/data-backup/ 2>/dev/null || true
            echo "Backed up data/download_summary.json"
          fi
          
          echo "Data backup completed"

      - name: Run DNS Toolkit Pipeline
        run: |
          echo "Running DNS toolkit pipeline in '${{ env.PIPELINE_MODE }}' mode..."
          
          # Step 1: Download (conditional)
          if [[ "${{ env.PIPELINE_MODE }}" == "full-pipeline" || "${{ env.PIPELINE_MODE }}" == "refresh-cache" ]]; then
            echo "Step 1: Downloading fresh data..."
            ./bin/dns-toolkit download
            echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC')" > data/download/.cache_timestamp
            echo "Downloaded: $(find data/download -type f 2>/dev/null | wc -l) files"
          else
            echo "Step 1: Using cached data (skipping download)"
            echo "Using cache: $(find data/download -type f 2>/dev/null | wc -l) files"
          fi
          
          # Core Processing Steps
          echo "Step 2: Processing data..."
          ./bin/dns-toolkit process
          ./bin/dns-toolkit consolidate
          ./bin/dns-toolkit consolidate groups
          ./bin/dns-toolkit consolidate categories
          ./bin/dns-toolkit top
          ./bin/dns-toolkit overlap
          ./bin/dns-toolkit generate output -i
          ./bin/dns-toolkit generate output-readme
          ./bin/dns-toolkit generate overlap-readme
          ./bin/dns-toolkit generate summaries-readme
          
          echo "✅ Pipeline core steps completed successfully."

      - name: Count and validate output files
        id: count-files
        run: |
          OUTPUT_COUNT=$(find data/output -type f ! -path "*/summaries/*" 2>/dev/null | wc -l)
          SUMMARY_COUNT=$(find data/output/summaries -name "*.json" 2>/dev/null | wc -l)
          DOWNLOAD_COUNT=$(find data/download -type f 2>/dev/null | wc -l)
          
          echo "output-count=$OUTPUT_COUNT" >> $GITHUB_OUTPUT
          echo "summary-count=$SUMMARY_COUNT" >> $GITHUB_OUTPUT
          echo "download-count=$DOWNLOAD_COUNT" >> $GITHUB_OUTPUT
          
          echo "Files generated:"
          echo "  - Output files: $OUTPUT_COUNT"
          echo "  - Summary files: $SUMMARY_COUNT"
          echo "  - Download files: $DOWNLOAD_COUNT"
          
          if [[ "$OUTPUT_COUNT" -eq 0 && "$SUMMARY_COUNT" -eq 0 ]]; then
            echo "::error::No output files generated. Pipeline might have failed silently."
            exit 1
          fi

      - name: Publish results
        if: env.SHOULD_PUBLISH == 'true'
        run: |
          echo "Publishing results..."
          
          # Create temporary directories for publishing
          mkdir -p /tmp/publish-data/{output,summaries}
          
          # Prepare output and summary files for publishing
          if [[ -d "data/output" ]]; then
            rsync -av --exclude='summaries/' data/output/ /tmp/publish-data/output/ 2>/dev/null || true
          fi
          
          if [[ -d "data/output/summaries" ]]; then
            cp -r data/output/summaries/* /tmp/publish-data/summaries/ 2>/dev/null || true
          fi
          
          # Store original branch and prepare publish script
          echo "ORIGINAL_BRANCH=$(git rev-parse --abbrev-ref HEAD)" >> $GITHUB_ENV
          
          # Execute publish script using specific variables
          if [[ "${{ steps.count-files.outputs.output-count }}" -gt 0 ]]; then
            echo "Publishing to output branch..."
            /bin/bash .github/scripts/publish-to-branch.sh output /tmp/publish-data/output
          fi
          
          if [[ "${{ steps.count-files.outputs.summary-count }}" -gt 0 ]]; then
            echo "Publishing to summaries branch..."
            /bin/bash .github/scripts/publish-to-branch.sh summaries /tmp/publish-data/summaries --monthly
          fi
          
          echo "✅ Publishing completed."

      - name: Restore data files
        if: env.PIPELINE_MODE == 'full-pipeline' && env.SHOULD_PUBLISH == 'true'
        run: |
          echo "Restoring data files after branch operations..."
          # Restore download directory and summary file from backup
          if [[ -d "/tmp/data-backup/download" ]]; then
            mkdir -p data
            cp -r /tmp/data-backup/download data/ 2>/dev/null || true
            echo "Restored data/download directory"
          fi
          if [[ -f "/tmp/data-backup/download_summary.json" ]]; then
            cp /tmp/data-backup/download_summary.json data/ 2>/dev/null || true
            echo "Restored data/download_summary.json"
          fi
          echo "Data restoration completed"

      - name: Generate cache key for save
        if: env.PIPELINE_MODE == 'refresh-cache' || env.PIPELINE_MODE == 'full-pipeline'
        id: cache-key
        run: |
          # Use date-based cache key to limit cache growth (daily rotation)
          CACHE_DATE=$(date -u '+%Y-%m-%d')
          CACHE_KEY="data-download-${{ runner.os }}-${{ hashFiles('data/config/sources*.json') }}-${CACHE_DATE}-v3"
          echo "cache-key=$CACHE_KEY" >> $GITHUB_OUTPUT
          echo "Generated cache key: $CACHE_KEY"

      - name: Save data cache
        if: (env.PIPELINE_MODE == 'refresh-cache' || env.PIPELINE_MODE == 'full-pipeline') && (steps.count-files.outputs.download-count > 0)
        uses: actions/cache/save@v4
        with:
          path: |
            data/download
            data/download_summary.json
          key: ${{ steps.cache-key.outputs.cache-key }}
        continue-on-error: true
        id: cache-save-attempt

      - name: Cache save status check
        if: always() && (env.PIPELINE_MODE == 'refresh-cache' || env.PIPELINE_MODE == 'full-pipeline')
        run: |
          if [[ "${{ steps.cache-save-attempt.outcome }}" == "success" ]]; then
            echo "✅ Data cache saved successfully."
          else
            echo "⚠️ Data cache save failed or was skipped."
          fi

      - name: Final Summary
        if: always()
        run: |
          echo "## Pipeline Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Mode**: \`${{ env.PIPELINE_MODE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Publishing Enabled**: \`${{ env.SHOULD_PUBLISH }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Job Status**: \`${{ job.status }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Completed At**: $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add cache status details
          if [[ "${{ env.PIPELINE_MODE }}" == "refresh-cache" || "${{ env.PIPELINE_MODE }}" == "full-pipeline" ]]; then
            echo "### Cache Management" >> $GITHUB_STEP_SUMMARY
            echo "- **Cache Key (Save)**: \`${{ steps.cache-key.outputs.cache-key || 'N/A' }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Cache Save Status**: \`${{ steps.cache-save-attempt.outcome || 'N/A' }}\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Add file counts
          if [[ "${{ env.PIPELINE_MODE }}" == "use-cache" || "${{ env.PIPELINE_MODE }}" == "full-pipeline" || "${{ env.PIPELINE_MODE }}" == "refresh-cache" ]] && [[ "${{ job.status }}" == "success" ]]; then
            echo "### File Counts" >> $GITHUB_STEP_SUMMARY
            echo "- **Downloaded Files**: \`${{ steps.count-files.outputs.download-count || 0 }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Generated Output Files**: \`${{ steps.count-files.outputs.output-count || 0 }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Generated Summary Files**: \`${{ steps.count-files.outputs.summary-count || 0 }}\`" >> $GITHUB_STEP_SUMMARY
            if [[ -f "data/download/.cache_timestamp" ]]; then
              echo "- **Data Cache Timestamp**: $(cat data/download/.cache_timestamp)" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "See full logs for details."