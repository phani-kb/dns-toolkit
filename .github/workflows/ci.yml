name: DNS Toolkit Daily Processing

# - Scheduled runs: full-pipeline mode with publishing
# - Push to main: use-cache mode without publishing (avoids cache conflicts)
# - Manual dispatch: user-selected mode with conditional publishing (refresh-cache and use-cache don't publish)
# - Pull Request: test-only mode

on:
  schedule:
    # run twice daily
    - cron: '0 22 * * *' # Daily at 10 PM UTC
    - cron: '0 10 * * *' # Daily at 10 AM UTC
  workflow_dispatch:
    inputs:
      mode:
        description: 'Pipeline mode'
        required: false
        default: 'full-pipeline'
        type: choice
        options:
          - 'full-pipeline'
          - 'use-cache'
          - 'refresh-cache'
  push:
    branches: [main]
  pull_request:
    branches: [main]

permissions:
  contents: read

concurrency:
  group: dns-toolkit-pipeline
  cancel-in-progress: false

env:
  GO_VERSION: '1.24'
  COVERAGE_THRESHOLD: 80
  GOLANGCI_LINT_VERSION: v2.1.6
  PUSH_TOKEN: ${{ secrets.PUSH_TOKEN }}

jobs:
  test-and-build:
    name: Test and Build
    runs-on: ubuntu-latest
    outputs:
      should-publish: ${{ steps.determine-mode.outputs.should-publish }}
      pipeline-mode: ${{ steps.determine-mode.outputs.pipeline-mode }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Install golangci-lint
        run: |
          curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | \
          sh -s -- -b $(go env GOPATH)/bin ${{ env.GOLANGCI_LINT_VERSION }}

      - name: Cache lint results
        uses: actions/cache@v4
        with:
          path: ~/.cache/golangci-lint
          key: ${{ runner.os }}-golangci-lint-${{ hashFiles('.golangci.yml', 'go.sum') }}
          restore-keys: |
            ${{ runner.os }}-golangci-lint-

      - name: Lint, Build, and Test
        env:
          DNS_TOOLKIT_TEST_MODE: true
          DNS_TOOLKIT_TEST_CONFIG_PATH: ${{ github.workspace }}/testdata/config.yml
        run: |
          echo "Running linter..."
          golangci-lint run ./... --timeout=5m

          echo "Building application..."
          go build ./...

          echo "Running tests with coverage..."
          PACKAGES=$(go list ./... | grep -v "/mocks" | grep -v "constants")
          go test -v -race -coverprofile=coverage.out -covermode=atomic $PACKAGES

          # Filter out test helpers from coverage
          if [ -f coverage.out ]; then
            echo "Filtering coverage report..."
            grep -v "test_helpers.go" coverage.out > tmp_filtered_coverage.out
            grep -v "testing_helpers.go" tmp_filtered_coverage.out > filtered_coverage.out
            mv filtered_coverage.out coverage.out
          fi

      - name: Check coverage
        run: |
          if [ -f coverage.out ]; then
            COVERAGE=$(go tool cover -func=coverage.out | grep total: | awk '{print $3}' | sed 's/%//')
            echo "Coverage: ${COVERAGE}%"
            if (( $(echo "$COVERAGE < $COVERAGE_THRESHOLD" | bc -l) )); then
              echo "::error::Coverage ${COVERAGE}% is below threshold ${COVERAGE_THRESHOLD}%"
              exit 1
            fi
            echo "::notice::Coverage check passed: ${COVERAGE}%"
          else
            echo "::warning::No coverage file found"
          fi

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.out
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          verbose: false
          override_commit: ${{ github.sha }}

      - name: Determine pipeline mode and publishing status
        id: determine-mode
        run: |
          # Default to test-only and no publish
          MODE="test-only"
          PUBLISH="false"
          MESSAGE="Other event - tests only"

          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            MODE="test-only"
            PUBLISH="false"
            MESSAGE="Pull request - tests only"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            MODE="${{ github.event.inputs.mode }}"
            if [[ "$MODE" == "refresh-cache" || "$MODE" == "use-cache" ]]; then
              PUBLISH="false"
            else
              PUBLISH="true"
            fi
            MESSAGE="Manual dispatch - Mode: $MODE"
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            MODE="full-pipeline"
            PUBLISH="true"
            MESSAGE="Scheduled event - Mode: $MODE"
          elif [[ "${{ github.event_name }}" == "push" && "${{ github.ref }}" == "refs/heads/main" ]]; then
            MODE="use-cache"
            PUBLISH="false"
            MESSAGE="Push to main - Mode: $MODE (use cache, no publish)"
          fi

          echo "::notice::$MESSAGE"
          echo "pipeline-mode=$MODE" >> $GITHUB_OUTPUT
          echo "should-publish=$PUBLISH" >> $GITHUB_OUTPUT

  publish:
    name: DNS Toolkit Pipeline
    runs-on: ubuntu-latest
    needs: test-and-build
    if: needs.test-and-build.outputs.pipeline-mode != 'test-only'
    timeout-minutes: 20
    permissions:
      contents: write
      actions: read
      pull-requests: write

    env:
      PIPELINE_MODE: ${{ needs.test-and-build.outputs.pipeline-mode }}
      SHOULD_PUBLISH: ${{ needs.test-and-build.outputs.should-publish }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          persist-credentials: true

      - name: Configure Git
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          git config pull.rebase false
          git config push.default simple

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Check GitHub CLI
        run: |
          if ! command -v gh &> /dev/null; then
            echo "GitHub CLI NOT pre-installed"
            exit 1
          else
            gh --version
          fi

      - name: Build DNS toolkit and prepare data directories
        run: |
          echo "Building DNS toolkit..."
          go build -o bin/dns-toolkit .
          chmod +x bin/dns-toolkit
          mkdir -p data/{download,output}
          echo "Build completed successfully"

      - name: Display pipeline mode summary
        run: |
          echo "## Pipeline Mode: ${{ env.PIPELINE_MODE }}" >> $GITHUB_STEP_SUMMARY
          echo "**Publishing**: ${{ env.SHOULD_PUBLISH }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          case "${{ env.PIPELINE_MODE }}" in
            "use-cache")
              echo "- **Actions**: Restore cache, skip download, process" >> $GITHUB_STEP_SUMMARY
              echo "- **Publishing**: Disabled (to avoid cache conflicts unless explicitly true)" >> $GITHUB_STEP_SUMMARY
              echo "- **Requirement**: Cache must exist or pipeline will fail" >> $GITHUB_STEP_SUMMARY
              ;;
            "refresh-cache")
              echo "- **Actions**: Download fresh data, process, save cache" >> $GITHUB_STEP_SUMMARY
              echo "- **Publishing**: Disabled (focus on cache refresh)" >> $GITHUB_STEP_SUMMARY
              ;;
            "full-pipeline")
              echo "- **Actions**: Download fresh data, process, publish, save cache" >> $GITHUB_STEP_SUMMARY
              echo "- **Note**: This is the default mode for scheduled runs" >> $GITHUB_STEP_SUMMARY
              ;;
          esac

      - name: Restore data cache
        uses: actions/cache/restore@v4
        id: cache-restore
        with:
          path: |
            data/download
            data/download_summary.json
          key: data-download-${{ runner.os }}-${{ hashFiles('data/config/sources*.json') }}-v3
          restore-keys: |
            data-download-${{ runner.os }}-${{ hashFiles('data/config/sources*.json') }}-
            data-download-${{ runner.os }}-

      - name: Validate cache (for use-cache & refresh-cache modes)
        if: env.PIPELINE_MODE == 'use-cache' || env.PIPELINE_MODE == 'refresh-cache'
        run: |
          echo "Validating cache availability..."
          echo "Cache key used: data-download-${{ runner.os }}-${{ hashFiles('data/config/sources*.json') }}-v3"
          echo "Cache hit: ${{ steps.cache-restore.outputs.cache-hit }}"

          # Check if cache was restored (either exact match or via restore-keys)
          CACHE_RESTORED_FROM="${{ steps.cache-restore.outputs.cache-primary-key }}"
          if [[ -z "$CACHE_RESTORED_FROM" ]]; then
            CACHE_RESTORED_FROM="${{ steps.cache-restore.outputs.cache-matched-key }}"
          fi
          if [[ "${{ steps.cache-restore.outputs.cache-hit }}" != "true" && -z "$CACHE_RESTORED_FROM" ]]; then
            echo "::error::Cache MISS. '${{ env.PIPELINE_MODE }}' mode requires an existing cache."
            exit 1
          fi

          if [[ ! -d "data/download" ]] || [[ -z "$(ls -A data/download 2>/dev/null)" ]]; then
            echo "::error::Cache hit reported, but data/download directory is empty or missing."
            exit 1
          fi

          if [[ "${{ env.PIPELINE_MODE }}" == "use-cache" && ! -f "data/download_summary.json" ]]; then
            echo "::error::'use-cache' mode requires 'data/download_summary.json' but it's missing from cache."
            exit 1
          fi

          echo "✅ Cache validated successfully."

          if [[ "${{ steps.cache-restore.outputs.cache-hit }}" == "true" ]]; then
            echo "Cache: Exact key match"
            echo "Key: ${{ steps.cache-restore.outputs.cache-primary-key }}"
          else
            echo "Cache: Restored via fallback key"
            echo "Matched key: $CACHE_RESTORED_FROM"
          fi

          echo "Cache contains $(find data/download -type f 2>/dev/null | wc -l) files."
          DOWNLOAD_SIZE=$(du -sh data/download 2>/dev/null | cut -f1 || echo "0")
          echo "Cache size: $DOWNLOAD_SIZE"
          if [[ -f "data/download/.cache_timestamp" ]]; then
            echo "Cache timestamp: $(cat data/download/.cache_timestamp)"
          fi

      - name: Backup data files
        if: env.PIPELINE_MODE == 'full-pipeline' && needs.test-and-build.outputs.should-publish == 'true'
        run: |
          echo "Backing up data files for branch switching..."
          mkdir -p /tmp/data-backup

          # Backup download directory and summary file
          if [[ -d "data/download" ]]; then
            cp -r data/download /tmp/data-backup/ 2>/dev/null || true
            echo "Backed up data/download directory"
          fi

          if [[ -f "data/download_summary.json" ]]; then
            cp data/download_summary.json /tmp/data-backup/ 2>/dev/null || true
            echo "Backed up data/download_summary.json"
          fi

          echo "Data backup completed"

      - name: Run DNS Toolkit Pipeline
        id: pipeline
        run: |
          echo "Running DNS toolkit pipeline in '${{ env.PIPELINE_MODE }}' mode..."

          # Step 0: Update allowlists
          ALLOWLIST_UPDATED="false"
          if [[ "${{ env.PIPELINE_MODE }}" == "full-pipeline" || "${{ env.PIPELINE_MODE }}" == "refresh-cache" ]]; then
            echo "Updating allowlists..."
            ./bin/dns-toolkit generate allowlist --overwrite
            echo "Allowlists updated successfully."

            # Check if allowlist files were modified
            if ! git diff --quiet -- data/custom/allowlist_*.txt; then
              echo "Allowlist files were modified..."
              ALLOWLIST_UPDATED="true"
              
              git add data/custom/allowlist_*.txt
              git commit -m "Auto-update: Refresh allowlist files (CI run ${{ github.run_number }}, mode: ${{ env.PIPELINE_MODE }})" || true
              echo "Allowlist changes committed locally."
              
              if [[ -f ".github/scripts/push-to-main.sh" ]]; then
                echo "Attempting to push allowlist changes to separate branch for PR..."
                export PUSH_TOKEN="${{ secrets.PUSH_TOKEN }}"
                export GITHUB_REPOSITORY="${{ github.repository }}"
                export GITHUB_RUN_NUMBER="${{ github.run_number }}"

                # Reset to get the changes back for pushing
                git reset --soft HEAD~1
                
                if ./.github/scripts/push-to-main.sh "data/custom/allowlist_*.txt" "Auto-update: Refresh allowlist files" "update-allowlist"; then
                  echo "Allowlist changes pushed to separate branch successfully"
                else
                  echo "Push to separate branch failed, committing locally instead"
                  git add data/custom/allowlist_*.txt
                  git commit -m "Auto-update: Refresh allowlist files (CI run ${{ github.run_number }}, mode: ${{ env.PIPELINE_MODE }})" || true
                fi
              fi
            else
              echo "No changes detected in allowlist files"
            fi
          fi

          echo "allowlist-updated=$ALLOWLIST_UPDATED" >> $GITHUB_OUTPUT
          # Step 1: Download (conditional)
          if [[ "${{ env.PIPELINE_MODE }}" == "full-pipeline" ]]; then # || "${{ env.PIPELINE_MODE }}" == "refresh-cache"
            echo "Step 1: Downloading fresh data..."
            ./bin/dns-toolkit download
            echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC')" > data/download/.cache_timestamp
            DOWNLOAD_COUNT=$(find data/download -type f 2>/dev/null | wc -l)
            DOWNLOAD_SIZE=$(du -sh data/download 2>/dev/null | cut -f1 || echo "0")
            echo "Downloaded: $DOWNLOAD_COUNT files ($DOWNLOAD_SIZE)"
          else
            echo "Step 1: Using cached data (skipping download)"
            CACHED_COUNT=$(find data/download -type f 2>/dev/null | wc -l)
            CACHED_SIZE=$(du -sh data/download 2>/dev/null | cut -f1 || echo "0")
            echo "Using cache: $CACHED_COUNT files ($CACHED_SIZE)"
          fi

          # Core Processing Steps
          echo "Step 2: Processing data..."
          ./bin/dns-toolkit process
          ./bin/dns-toolkit consolidate
          ./bin/dns-toolkit consolidate groups
          ./bin/dns-toolkit consolidate categories
          # ./bin/dns-toolkit top
          # ./bin/dns-toolkit overlap
          ./bin/dns-toolkit generate output -i
          ./bin/dns-toolkit generate output-readme
          # ./bin/dns-toolkit generate overlap-readme
          ./bin/dns-toolkit generate summaries-readme
          ./bin/dns-toolkit generate stats-readme
          ./bin/dns-toolkit generate credits

          echo "✅ Pipeline core steps completed successfully."

      - name: Count and validate output files
        id: count-files
        run: |
          OUTPUT_COUNT=$(find data/output -type f ! -path "*/summaries/*" 2>/dev/null | wc -l)
          SUMMARY_COUNT=$(find data/output/summaries -name "*.json" 2>/dev/null | wc -l)
          DOWNLOAD_COUNT=$(find data/download -type f 2>/dev/null | wc -l)
          DOWNLOAD_SIZE=$(du -sh data/download 2>/dev/null | cut -f1 || echo "0")

          echo "output-count=$OUTPUT_COUNT" >> $GITHUB_OUTPUT
          echo "summary-count=$SUMMARY_COUNT" >> $GITHUB_OUTPUT
          echo "download-count=$DOWNLOAD_COUNT" >> $GITHUB_OUTPUT
          echo "download-size=$DOWNLOAD_SIZE" >> $GITHUB_OUTPUT

          echo "Files generated:"
          echo "  - Output files: $OUTPUT_COUNT"
          echo "  - Summary files: $SUMMARY_COUNT"
          echo "  - Download files: $DOWNLOAD_COUNT ($DOWNLOAD_SIZE)"

          if [[ "$OUTPUT_COUNT" -eq 0 && "$SUMMARY_COUNT" -eq 0 ]]; then
            echo "::error::No output files generated. Pipeline might have failed silently."
            exit 1
          fi

      - name: Commit all pending changes before publishing
        if: env.SHOULD_PUBLISH == 'true'
        run: |
          echo "Checking for any uncommitted changes before publishing..."

          # Check for any uncommitted changes
          if [[ -n "$(git status --porcelain)" ]]; then
            echo "Found uncommitted changes:"
            git status --porcelain
            
            # Handle README.md changes
            if ! git diff --quiet -- README.md; then
              echo "README.md has been modified, handling README changes..."

              git add README.md || true
              git commit -m "Auto-update: Generated README (CI run ${{ github.run_number }}, mode: ${{ env.PIPELINE_MODE }}) [skip ci]" || true
              echo "README changes committed locally."

              if [[ -f ".github/scripts/push-to-main.sh" ]]; then
                echo "Attempting to push README changes to separate branch for PR..."
                export PUSH_TOKEN="${{ secrets.PUSH_TOKEN }}"
                export GITHUB_REPOSITORY="${{ github.repository }}"
                export GITHUB_RUN_NUMBER="${{ github.run_number }}"

                # Reset to get the changes back for pushing  
                git reset --soft HEAD~1

                if ./.github/scripts/push-to-main.sh "README.md" "Auto-update: Generated README (mode: ${{ env.PIPELINE_MODE }})" "update-readme"; then
                  echo "README changes pushed to separate branch successfully"
                else
                  echo "README push failed, committing locally instead"
                  git add README.md || true
                  git commit -m "Auto-update: Generated README (CI run ${{ github.run_number }}, mode: ${{ env.PIPELINE_MODE }}) [skip ci]" || true
                fi
              fi
            fi
            
            if [[ -n "$(git status --porcelain)" ]]; then
              echo "Committing remaining uncommitted changes..."
              git add -A
              git commit -m "Auto-commit: Pending changes before publishing (CI run ${{ github.run_number }}, mode: ${{ env.PIPELINE_MODE }}) [skip ci]" || true
              echo "All changes committed locally"
            fi
          else
            echo "No uncommitted changes detected"
          fi

          CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
          if [[ "$CURRENT_BRANCH" != "main" ]]; then
            echo "Not on main branch (currently on $CURRENT_BRANCH), switching to main"
            git checkout main || {
              echo "Failed to checkout main branch"
              exit 1
            }
          fi

      - name: Publish results
        if: env.SHOULD_PUBLISH == 'true'
        run: |
          echo "Publishing results..."

          CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
          if [[ "$CURRENT_BRANCH" != "main" ]]; then
            echo "Warning: Not on main branch (currently on $CURRENT_BRANCH), switching to main"
            git checkout main || {
              echo "Error: Failed to checkout main branch before publishing"
              exit 1
            }
          fi

          if [[ -n "$(git status --porcelain)" ]]; then
            echo "Error: Working directory is not clean before publishing"
            git status --porcelain
            echo "Previous step failed to clean working directory"
            exit 1
          fi

          echo "Working directory is clean, proceeding with publishing..."

          # Create temporary directories for publishing
          mkdir -p /tmp/publish-data/{output,summaries}

          # Prepare output and summary files for publishing
          if [[ -d "data/output" ]]; then
            rsync -av --exclude='summaries/' data/output/ /tmp/publish-data/output/ 2>/dev/null || true
          fi

          if [[ -d "data/output/summaries" ]]; then
            cp -r data/output/summaries/* /tmp/publish-data/summaries/ 2>/dev/null || true
          fi

          echo "ORIGINAL_BRANCH=$(git rev-parse --abbrev-ref HEAD)" >> $GITHUB_ENV

          if [[ "${{ steps.count-files.outputs.output-count }}" -gt 0 ]]; then
            echo "Publishing to output branch..."
            /bin/bash .github/scripts/publish-to-branch.sh output /tmp/publish-data/output
          fi

          if [[ "${{ steps.count-files.outputs.summary-count }}" -gt 0 ]]; then
            echo "Publishing to summaries branch..."
            /bin/bash .github/scripts/publish-to-branch.sh summaries /tmp/publish-data/summaries --monthly
          fi

          echo "✅ Publishing completed."

      - name: Restore data files
        if: env.PIPELINE_MODE == 'full-pipeline' && env.SHOULD_PUBLISH == 'true'
        run: |
          echo "Restoring data files after branch operations..."
          # Restore download directory and summary file from backup
          if [[ -d "/tmp/data-backup/download" ]]; then
            mkdir -p data
            cp -r /tmp/data-backup/download data/ 2>/dev/null || true
            echo "Restored data/download directory"
          fi
          if [[ -f "/tmp/data-backup/download_summary.json" ]]; then
            cp /tmp/data-backup/download_summary.json data/ 2>/dev/null || true
            echo "Restored data/download_summary.json"
          fi
          echo "Data restoration completed"

      - name: Generate cache key for save
        if: env.PIPELINE_MODE == 'refresh-cache' || env.PIPELINE_MODE == 'full-pipeline'
        id: cache-key
        run: |
          # Use date-based cache key to limit cache growth (daily rotation)
          CACHE_DATE=$(date -u '+%Y-%m-%d')
          CACHE_KEY="data-download-${{ runner.os }}-${{ hashFiles('data/config/sources*.json') }}-${CACHE_DATE}-v3"
          echo "cache-key=$CACHE_KEY" >> $GITHUB_OUTPUT
          echo "Generated cache key: $CACHE_KEY"

      - name: Save data cache
        if: (env.PIPELINE_MODE == 'refresh-cache' || env.PIPELINE_MODE == 'full-pipeline') && (steps.count-files.outputs.download-count > 0)
        uses: actions/cache/save@v4
        with:
          path: |
            data/download
            data/download_summary.json
          key: ${{ steps.cache-key.outputs.cache-key }}
        continue-on-error: true
        id: cache-save-attempt

      - name: Cache save status check
        if: always() && (env.PIPELINE_MODE == 'refresh-cache' || env.PIPELINE_MODE == 'full-pipeline')
        run: |
          if [[ "${{ steps.cache-save-attempt.outcome }}" == "success" ]]; then
            echo "✅ Data cache saved successfully."
            echo "Cached: ${{ steps.count-files.outputs.download-count }} files (${{ steps.count-files.outputs.download-size }})"
          else
            echo "⚠️ Data cache save failed or was skipped."
          fi

      - name: Final Summary
        if: always()
        run: |
          echo "## Pipeline Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Mode**: \`${{ env.PIPELINE_MODE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Publishing Enabled**: \`${{ env.SHOULD_PUBLISH }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Job Status**: \`${{ job.status }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Completed At**: $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Add cache status details
          if [[ "${{ env.PIPELINE_MODE }}" == "refresh-cache" || "${{ env.PIPELINE_MODE }}" == "full-pipeline" ]]; then
            echo "### Cache Management" >> $GITHUB_STEP_SUMMARY
            echo "- **Cache Key (Save)**: \`${{ steps.cache-key.outputs.cache-key || 'N/A' }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Cache Save Status**: \`${{ steps.cache-save-attempt.outcome || 'N/A' }}\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Add file counts
          if [[ "${{ env.PIPELINE_MODE }}" == "use-cache" || "${{ env.PIPELINE_MODE }}" == "full-pipeline" || "${{ env.PIPELINE_MODE }}" == "refresh-cache" ]] && [[ "${{ job.status }}" == "success" ]]; then
            echo "### File Counts" >> $GITHUB_STEP_SUMMARY
            echo "- **Downloaded Files**: \`${{ steps.count-files.outputs.download-count || 0 }}\` (\`${{ steps.count-files.outputs.download-size || '0' }}\`)" >> $GITHUB_STEP_SUMMARY
            echo "- **Generated Output Files**: \`${{ steps.count-files.outputs.output-count || 0 }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Generated Summary Files**: \`${{ steps.count-files.outputs.summary-count || 0 }}\`" >> $GITHUB_STEP_SUMMARY
            if [[ "${{ steps.pipeline.outputs.allowlist-updated }}" == "true" ]]; then
              echo "- **Allowlist Files**: Updated and committed locally" >> $GITHUB_STEP_SUMMARY
            fi
            if [[ -f "data/download/.cache_timestamp" ]]; then
              echo "- **Data Cache Timestamp**: $(cat data/download/.cache_timestamp)" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          echo "See full logs for details."
