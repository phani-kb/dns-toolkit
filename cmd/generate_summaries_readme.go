package cmd

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"time"

	c "github.com/phani-kb/dns-toolkit/internal/common"
	"github.com/phani-kb/dns-toolkit/internal/constants"
	u "github.com/phani-kb/dns-toolkit/internal/utils"
	"github.com/spf13/cobra"
)

var generateSummariesReadmeCmd = &cobra.Command{
	Use:   "summaries-readme",
	Short: "Generate README.md for summaries with summary information",
	Long:  "Generate a README.md for the summaries directory containing information about the last generated summary files.", // nolint:lll
	Run: func(cmd *cobra.Command, args []string) {
		if os.Getenv("DNS_TOOLKIT_TEST_MODE") == "true" {
			Logger.Debug("Skipping generate summaries readme command in test mode")
			return
		}

		Logger.Info("Generating README.md for summaries...")

		summariesDir := filepath.Join(constants.OutputDir, "summaries")
		if err := u.EnsureDirectoryExists(Logger, summariesDir); err != nil {
			Logger.Errorf("Failed to create summaries directory: %v", err)
			os.Exit(1)
		}

		readme := generateSummariesReadme()

		readmePath := filepath.Join(summariesDir, "README.md")
		if err := os.WriteFile(readmePath, []byte(readme), 0644); err != nil {
			Logger.Errorf("Failed to write summaries README file: %v", err)
			os.Exit(1)
		}

		Logger.Infof("Successfully generated summaries README.md at %s", readmePath)
	},
}

// SummariesInfo holds information about summary files
type SummariesInfo struct {
	SummaryTypes  map[string]SummaryTypeInfo
	LastGenerated string
	TotalFiles    int
	OverallStats  OverallSummaryStats
}

type SummaryTypeInfo struct {
	LastUpdated string
	FileCount   int
}

type OverallSummaryStats struct {
	TotalSources         int
	TotalDownloads       int
	TotalProcessed       int
	TotalConsolidated    int
	TotalGroups          int
	TotalCategories      int
	TotalTopLists        int
	TotalOverlapAnalyzed int
}

func generateSummariesReadme() string {
	info := collectSummariesInfo()

	var sb strings.Builder

	sb.WriteString("# DNS Toolkit - Summary Files\n\n")
	sb.WriteString("This README provides an overview of the JSON summary files generated by the DNS Toolkit workflow. ")
	sb.WriteString("The statistics below are based on the last generated summary files for the current month.\n\n")
	sb.WriteString(fmt.Sprintf("**Last Generated:** %s\n\n", info.LastGenerated))

	// Quick overview
	sb.WriteString("## Overview\n\n")
	sb.WriteString("| Metric | Count |\n")
	sb.WriteString("|--------|-------|\n")
	sb.WriteString(fmt.Sprintf("| Total Summary Files | %d |\n", info.TotalFiles))
	sb.WriteString(fmt.Sprintf("| Summary Types | %d |\n", len(info.SummaryTypes)))
	sb.WriteString("\n")

	// Overall statistics
	sb.WriteString("## Overall Statistics\n\n")
	sb.WriteString("| Process | Count |\n")
	sb.WriteString("|---------|-------|\n")
	sb.WriteString(fmt.Sprintf("| Sources Configured | %d |\n", info.OverallStats.TotalSources))
	sb.WriteString(fmt.Sprintf("| Downloads Attempted | %d |\n", info.OverallStats.TotalDownloads))
	sb.WriteString(fmt.Sprintf("| Files Processed | %d |\n", info.OverallStats.TotalProcessed))
	sb.WriteString(fmt.Sprintf("| Files Consolidated | %d |\n", info.OverallStats.TotalConsolidated))
	sb.WriteString(fmt.Sprintf("| Groups Generated | %d |\n", info.OverallStats.TotalGroups))
	sb.WriteString(fmt.Sprintf("| Categories Generated | %d |\n", info.OverallStats.TotalCategories))
	sb.WriteString(fmt.Sprintf("| Top Lists Generated | %d |\n", info.OverallStats.TotalTopLists))
	sb.WriteString(fmt.Sprintf("| Sources Analyzed for Overlap | %d |\n", info.OverallStats.TotalOverlapAnalyzed))
	sb.WriteString("\n")

	sb.WriteString("## Summary Files\n\n")

	var types []string
	for summaryType := range info.SummaryTypes {
		types = append(types, summaryType)
	}
	sort.Strings(types)

	for _, summaryType := range types {
		typeInfo := info.SummaryTypes[summaryType]
		sb.WriteString(fmt.Sprintf("### %s\n", summaryType))
		sb.WriteString(fmt.Sprintf("**Last Updated:** %s  \n", typeInfo.LastUpdated))

		// Add specific stats for each summary type
		stats := getDetailedStatsForSummaryType(summaryType)
		if stats != "" {
			sb.WriteString(stats)
		}
		sb.WriteString("\n")
	}

	sb.WriteString("## About\n\n")
	sb.WriteString(fmt.Sprintf(
		"These summaries are automatically generated by the [DNS Toolkit](%s) ",
		constants.GitHubRepoURL,
	))
	sb.WriteString("as part of the daily processing pipeline.\n\n")

	return sb.String()
}

func collectSummariesInfo() *SummariesInfo {
	info := &SummariesInfo{
		LastGenerated: time.Now().Format("2006-01-02 15:04:05 UTC"),
		SummaryTypes:  make(map[string]SummaryTypeInfo),
		OverallStats:  OverallSummaryStats{},
	}

	summariesDir := filepath.Join(constants.OutputDir, "summaries")
	if _, err := os.Stat(summariesDir); os.IsNotExist(err) {
		Logger.Warnf("Summaries directory does not exist: %s", summariesDir)
		return info
	}

	files, err := os.ReadDir(summariesDir)
	if err != nil {
		Logger.Warnf("Failed to read summaries directory: %v", err)
		return info
	}

	// Count files by type and collect information
	for _, file := range files {
		if file.IsDir() || !strings.HasSuffix(file.Name(), ".json") {
			continue
		}

		info.TotalFiles++

		// Get file info
		filePath := filepath.Join(summariesDir, file.Name())
		fileInfo, err := os.Stat(filePath)
		if err != nil {
			continue
		}

		summaryType := file.Name()
		typeInfo := info.SummaryTypes[summaryType]
		typeInfo.FileCount = 1 // Each summary type typically has one file
		typeInfo.LastUpdated = fileInfo.ModTime().Format("2006-01-02 15:04")
		info.SummaryTypes[summaryType] = typeInfo

		// Collect overall statistics from summary files
		collectOverallStatsFromFile(filePath, file.Name(), &info.OverallStats)
	}

	return info
}

func getDetailedStatsForSummaryType(filename string) string {
	summariesDir := filepath.Join(constants.OutputDir, "summaries")
	filePath := filepath.Join(summariesDir, filename)

	content, err := os.ReadFile(filePath)
	if err != nil {
		return ""
	}

	switch filename {
	case "download_summary.json":
		var downloadSummaries []c.DownloadSummary
		if err := json.Unmarshal(content, &downloadSummaries); err != nil {
			return ""
		}

		successCount := 0
		failedCount := 0
		typeCount := make(map[string]int)

		for _, summary := range downloadSummaries {
			if summary.Error != "" {
				failedCount++
			} else {
				successCount++
			}

			for _, sourceType := range summary.Types {
				typeCount[sourceType.Name]++
			}
		}

		var result strings.Builder
		result.WriteString(fmt.Sprintf("**Sources:** %d total, %d successful, %d failed  \n",
			len(downloadSummaries), successCount, failedCount))

		if len(typeCount) > 0 {
			result.WriteString("**Types:** ")
			var types []string
			for t, count := range typeCount {
				types = append(types, fmt.Sprintf("%s (%d)", t, count))
			}
			sort.Strings(types)
			result.WriteString(strings.Join(types, ", "))
			result.WriteString("  \n")
		}

		return result.String()

	case "processed_summary.json":
		var processedSummaries []c.ProcessedSummary
		if err := json.Unmarshal(content, &processedSummaries); err != nil {
			return ""
		}

		totalValid := 0
		totalInvalid := 0
		typeCount := make(map[string]int)

		for _, summary := range processedSummaries {
			totalValid += len(summary.ValidFiles)
			totalInvalid += len(summary.InvalidFiles)

			for _, file := range summary.ValidFiles {
				typeCount[file.GenericSourceType]++
			}
		}

		var result strings.Builder
		result.WriteString(fmt.Sprintf("**Sources:** %d processed  \n", len(processedSummaries)))
		result.WriteString(fmt.Sprintf("**Files:** %d valid, %d invalid  \n", totalValid, totalInvalid))

		if len(typeCount) > 0 {
			result.WriteString("**Types:** ")
			var types []string
			for t, count := range typeCount {
				types = append(types, fmt.Sprintf("%s (%d)", t, count))
			}
			sort.Strings(types)
			result.WriteString(strings.Join(types, ", "))
			result.WriteString("  \n")
		}

		return result.String()

	case "consolidated_summary.json":
		var consolidatedSummaries []c.ConsolidatedSummary
		if err := json.Unmarshal(content, &consolidatedSummaries); err != nil {
			return ""
		}

		totalFiles := 0
		totalEntries := 0
		typeCount := make(map[string]int)

		for _, summary := range consolidatedSummaries {
			totalFiles += summary.FilesCount
			totalEntries += summary.Count
			typeCount[summary.Type]++
		}

		var result strings.Builder
		result.WriteString(fmt.Sprintf("**Files:** %d consolidated  \n", totalFiles))
		result.WriteString(fmt.Sprintf("**Entries:** %s total  \n", formatNumber(totalEntries)))

		if len(typeCount) > 0 {
			result.WriteString("**Types:** ")
			var types []string
			for t, count := range typeCount {
				types = append(types, fmt.Sprintf("%s (%d)", t, count))
			}
			sort.Strings(types)
			result.WriteString(strings.Join(types, ", "))
			result.WriteString("  \n")
		}

		return result.String()

	case "consolidated_categories_summary.json":
		var categoriesSummaries []c.ConsolidatedSummary
		if err := json.Unmarshal(content, &categoriesSummaries); err != nil {
			return ""
		}

		totalFiles := 0
		totalEntries := 0
		categoryCount := make(map[string]int)

		for _, summary := range categoriesSummaries {
			totalFiles += summary.FilesCount
			totalEntries += summary.Count
			if summary.Category != "" {
				categoryCount[summary.Category]++
			}
		}

		var result strings.Builder
		result.WriteString(fmt.Sprintf("**Categories:** %d processed  \n", len(categoryCount)))
		result.WriteString(fmt.Sprintf("**Files:** %d consolidated  \n", totalFiles))
		result.WriteString(fmt.Sprintf("**Entries:** %s total  \n", formatNumber(totalEntries)))

		if len(categoryCount) > 0 {
			result.WriteString("**Categories:** ")
			var categories []string
			for c, count := range categoryCount {
				categories = append(categories, fmt.Sprintf("%s (%d)", c, count))
			}
			sort.Strings(categories)
			result.WriteString(strings.Join(categories, ", "))
			result.WriteString("  \n")
		}

		return result.String()

	case "consolidated_groups_summary.json":
		var groupsSummaries []c.ConsolidatedSummary
		if err := json.Unmarshal(content, &groupsSummaries); err != nil {
			return ""
		}

		totalFiles := 0
		totalEntries := 0
		groupCount := make(map[string]int)

		for _, summary := range groupsSummaries {
			totalFiles += summary.FilesCount
			totalEntries += summary.Count
			if summary.Group != "" {
				groupCount[summary.Group]++
			}
		}

		var result strings.Builder
		result.WriteString(fmt.Sprintf("**Groups:** %d processed  \n", len(groupCount)))
		result.WriteString(fmt.Sprintf("**Files:** %d consolidated  \n", totalFiles))
		result.WriteString(fmt.Sprintf("**Entries:** %s total  \n", formatNumber(totalEntries)))

		if len(groupCount) > 0 {
			result.WriteString("**Groups:** ")
			var groups []string
			for g, count := range groupCount {
				groups = append(groups, fmt.Sprintf("%s (%d)", g, count))
			}
			sort.Strings(groups)
			result.WriteString(strings.Join(groups, ", "))
			result.WriteString("  \n")
		}

		return result.String()

	case "top_summary.json":
		var topSummaries []c.TopSummary
		if err := json.Unmarshal(content, &topSummaries); err != nil {
			return ""
		}

		totalEntries := 0
		typeMinSources := make(map[string][]string) // type -> list of "min+X (count)"

		for _, summary := range topSummaries {
			totalEntries += summary.Count
			minStr := fmt.Sprintf("%d+ (%d)", summary.MinSources, summary.Count)
			typeMinSources[summary.GenericSourceType] = append(typeMinSources[summary.GenericSourceType], minStr)
		}

		var result strings.Builder
		result.WriteString(fmt.Sprintf("**Types:** %d analyzed  \n", len(topSummaries)))
		result.WriteString(fmt.Sprintf("**Top Entries:** %s total  \n", formatNumber(totalEntries)))

		if len(typeMinSources) > 0 {
			result.WriteString("**Details:** ")
			var types []string
			for t := range typeMinSources {
				types = append(types, t)
			}
			sort.Strings(types)

			var details []string
			for _, t := range types {
				minList := typeMinSources[t]
				details = append(details, fmt.Sprintf("%s (%s)", t, strings.Join(minList, ", ")))
			}
			result.WriteString(strings.Join(details, "; "))
			result.WriteString("  \n")
		}

		return result.String()

	case "overlap_summary.json":
		var overlapSummaries []c.OverlapSummary
		if err := json.Unmarshal(content, &overlapSummaries); err != nil {
			return ""
		}

		totalEntries := 0
		totalUnique := 0
		typeCount := make(map[string]int)

		for _, summary := range overlapSummaries {
			totalEntries += summary.Count
			totalUnique += summary.Unique
			typeCount[summary.Type]++
		}

		uniquePercentage := 0.0
		if totalEntries > 0 {
			uniquePercentage = (float64(totalUnique) / float64(totalEntries)) * 100
		}

		var result strings.Builder
		result.WriteString(fmt.Sprintf("**Sources:** %d analyzed  \n", len(overlapSummaries)))
		result.WriteString(fmt.Sprintf("**Total Entries:** %s  \n", formatNumber(totalEntries)))
		result.WriteString(
			fmt.Sprintf("**Unique Entries:** %s (%.1f%%)  \n", formatNumber(totalUnique), uniquePercentage),
		)

		if len(typeCount) > 0 {
			result.WriteString("**Types:** ")
			var types []string
			for t, count := range typeCount {
				types = append(types, fmt.Sprintf("%s (%d)", t, count))
			}
			sort.Strings(types)
			result.WriteString(strings.Join(types, ", "))
			result.WriteString("  \n")
		}

		return result.String()

	default:
		return ""
	}
}

func collectOverallStatsFromFile(filePath, filename string, stats *OverallSummaryStats) {
	content, err := os.ReadFile(filePath)
	if err != nil {
		return
	}

	switch filename {
	case "download_summary.json":
		var downloadSummaries []c.DownloadSummary
		if err := json.Unmarshal(content, &downloadSummaries); err == nil {
			stats.TotalDownloads = len(downloadSummaries)
			// Count unique sources
			sourceMap := make(map[string]bool)
			for _, summary := range downloadSummaries {
				sourceMap[summary.Name] = true
			}
			stats.TotalSources = len(sourceMap)
		}

	case "processed_summary.json":
		var processedSummaries []c.ProcessedSummary
		if err := json.Unmarshal(content, &processedSummaries); err == nil {
			stats.TotalProcessed = len(processedSummaries)
		}

	case "consolidated_summary.json":
		var consolidatedSummaries []c.ConsolidatedSummary
		if err := json.Unmarshal(content, &consolidatedSummaries); err == nil {
			stats.TotalConsolidated = len(consolidatedSummaries)
		}

	case "consolidated_groups_summary.json":
		var groupsSummaries []c.ConsolidatedSummary
		if err := json.Unmarshal(content, &groupsSummaries); err == nil {
			groupMap := make(map[string]bool)
			for _, summary := range groupsSummaries {
				if summary.Group != "" {
					groupMap[summary.Group] = true
				}
			}
			stats.TotalGroups = len(groupMap)
		}

	case "consolidated_categories_summary.json":
		var categoriesSummaries []c.ConsolidatedSummary
		if err := json.Unmarshal(content, &categoriesSummaries); err == nil {
			categoryMap := make(map[string]bool)
			for _, summary := range categoriesSummaries {
				if summary.Category != "" {
					categoryMap[summary.Category] = true
				}
			}
			stats.TotalCategories = len(categoryMap)
		}

	case "top_summary.json":
		var topSummaries []c.TopSummary
		if err := json.Unmarshal(content, &topSummaries); err == nil {
			stats.TotalTopLists = len(topSummaries)
		}

	case "overlap_summary.json":
		var overlapSummaries []c.OverlapSummary
		if err := json.Unmarshal(content, &overlapSummaries); err == nil {
			stats.TotalOverlapAnalyzed = len(overlapSummaries)
		}
	}
}

func init() {
	generateCmd.AddCommand(generateSummariesReadmeCmd)
}
